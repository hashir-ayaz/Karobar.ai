# -*- coding: utf-8 -*-
"""resume_parser.ipynb
This will have all the functions needed to parse resumes and store them

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NbpRl3OiV_-9E3_Np3eEG4_IUtjECe8Y
"""

# Install required libraries
# !pip install spacy pandas pymupdf
# !python -m spacy download en_core_web_lg

import spacy
import re
import pandas as pd
from collections import defaultdict
import fitz

# Load the SpaCy model
nlp = spacy.load("en_core_web_lg")


def extract_resume_sections(resume_text):
    sections = {
        "EXPERIENCE": ["experience", "work experience", "employment"],
        "EDUCATION": ["education", "academic background", "academic"],
        "SKILLS": ["skills", "technical skills", "competencies"],
        "PROJECTS": ["projects", "project experience"],
        "CERTIFICATIONS": ["certifications", "certificates", "credentials"],
    }
    extracted_content = defaultdict(list)
    lines = resume_text.split("\n")
    current_section = None
    for line in lines:
        line = line.strip()
        if not line:
            continue
        found_section = False
        for section, keywords in sections.items():
            if any(keyword.lower() in line.lower() for keyword in keywords):
                current_section = section
                found_section = True
                break
        if not found_section and current_section:
            extracted_content[current_section].append(line)
    return extracted_content


def extract_skills(skills_text):
    doc = nlp(" ".join(skills_text))
    tech_skills = []
    for token in doc:
        if token.is_alpha and len(token.text) > 1 and not token.is_stop:
            tech_skills.append(token.text)
    return list(set(tech_skills))


def extract_experience(experience_text):
    experiences = []
    current_exp = {}
    for line in experience_text:
        if "|" in line:
            parts = line.split("|")
            if len(parts) >= 2:
                if current_exp and "title" in current_exp:
                    experiences.append(current_exp)
                current_exp = {"title": parts[0].strip(), "company": parts[1].strip()}
        date_pattern = r"(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \d{4}\s*-\s*(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \d{4}|Present"
        date_match = re.search(date_pattern, line)
        if date_match and "title" in current_exp:
            current_exp["duration"] = date_match.group(0)
        if (
            line.strip().startswith("-")
            or re.match(r"^\â€¢\s", line)
            or re.match(r"^\d+\.\s", line)
        ):
            if "responsibilities" not in current_exp:
                current_exp["responsibilities"] = []
            current_exp["responsibilities"].append(line.strip())
    if current_exp and "title" in current_exp:
        experiences.append(current_exp)
    return experiences


def extract_education(education_text):
    education = []
    current_edu = {}
    for line in education_text:
        if "|" in line:
            parts = line.split("|")
            if len(parts) >= 2:
                if current_edu and "degree" in current_edu:
                    education.append(current_edu)
                current_edu = {
                    "degree": parts[0].strip(),
                    "institution": parts[1].strip(),
                }
                gpa_pattern = r"CGPA[:=]?\s*(\d+\.\d+)"
                gpa_match = re.search(gpa_pattern, line)
                if gpa_match:
                    current_edu["gpa"] = gpa_match.group(1)
    if current_edu and "degree" in current_edu:
        education.append(current_edu)
    return education


def analyze_resume(resume_text):
    sections = extract_resume_sections(resume_text)
    results = {
        "skills": extract_skills(sections.get("SKILLS", [])),
        "experiences": extract_experience(sections.get("EXPERIENCE", [])),
        "education": extract_education(sections.get("EDUCATION", [])),
        "projects": sections.get("PROJECTS", []),
        "certifications": sections.get("CERTIFICATIONS", []),
    }
    return results


def extract_text_from_pdf(pdf_path):
    text = ""
    with fitz.open(pdf_path) as doc:
        for page in doc:
            text += page.get_text()
    return text


# extract_text_from_pdf("/content/Hashir_Ayaz_Resume.pdf")

# # Replace with your own resume file path
# resume_text = extract_text_from_pdf("/content/Hashir_Ayaz_Resume.pdf")
# resume_data = analyze_resume(resume_text)
# print(resume_data)

# """# After getting the resume data now we embed it"""
